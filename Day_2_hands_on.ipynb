{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "in this we dont have sentiment column so we make that with the help of review\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0        asin helpful  rating  \\\n",
      "1             1        5957  B002HJV4DE  [1, 1]       5   \n",
      "4             4        1776  B001A06VJ8  [0, 1]       4   \n",
      "5             5        3744  B0021L9YDK  [6, 6]       5   \n",
      "6             6       13641  B0038NN38W  [1, 1]       2   \n",
      "7             7        4448  B002AJ7X2C  [1, 1]       4   \n",
      "\n",
      "                                          reviewText   reviewTime  \\\n",
      "1  Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
      "4  I did not expect this type of book to be in li...  12 31, 2012   \n",
      "5  Aislinn is a little girl with big dreams. Afte...   12 7, 2009   \n",
      "6  This has the makings of a good story... unfort...  08 18, 2011   \n",
      "7  I got this because I like collaborated short s...   03 8, 2010   \n",
      "\n",
      "       reviewerID                                      reviewerName  \\\n",
      "1  A2RGNZ0TRF578I                                      Holly Butler   \n",
      "4  A3C9V987IQHOQD                                          Rjostler   \n",
      "5  A3J5NN6MJK4M4A         Aubrie A. Dionne \"Fantasy, Sci Fi Author\"   \n",
      "6   A531QY5K7JVXI                                           Chicano   \n",
      "7    AN8ELR6AHMMQ  Jessss \"I read to find stories that inspire m...   \n",
      "\n",
      "                                             summary  unixReviewTime  \\\n",
      "1                            Terrific menage scenes!      1381190400   \n",
      "4                                               Book      1356912000   \n",
      "5          A story of a little girl with big dreams.      1260144000   \n",
      "6  This story has potential but ultimately disapp...      1313625600   \n",
      "7                                      Good thriller      1268006400   \n",
      "\n",
      "   Sentiment  \n",
      "1        1.0  \n",
      "4        1.0  \n",
      "5        1.0  \n",
      "6        0.0  \n",
      "7        1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"G:\\\\Step_internship\\\\STEP_INTERNSHIP\\\\all_kindle_review.csv\")\n",
    "\n",
    "df['Sentiment'] = df['rating'].apply(lambda x: 1 if x > 3 else (0 if x < 3 else None))\n",
    "\n",
    "df.dropna(subset=['Sentiment'], inplace=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing the data\n",
    "convertiing to lower case and removing unnessary puntuation and special charactr etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\M.Vishnu\n",
      "[nltk_data]     Balaji\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0        asin helpful  rating  \\\n",
      "1             1        5957  B002HJV4DE  [1, 1]       5   \n",
      "4             4        1776  B001A06VJ8  [0, 1]       4   \n",
      "5             5        3744  B0021L9YDK  [6, 6]       5   \n",
      "6             6       13641  B0038NN38W  [1, 1]       2   \n",
      "7             7        4448  B002AJ7X2C  [1, 1]       4   \n",
      "\n",
      "                                          reviewText   reviewTime  \\\n",
      "1  great short read didnt want put read one sitti...   10 8, 2013   \n",
      "4  expect type book library pleased find price right  12 31, 2012   \n",
      "5  aislinn little girl big dreams death older bro...   12 7, 2009   \n",
      "6  makings good story unfortunately disappointsit...  08 18, 2011   \n",
      "7  got like collaborated short stories alot times...   03 8, 2010   \n",
      "\n",
      "       reviewerID                                      reviewerName  \\\n",
      "1  A2RGNZ0TRF578I                                      Holly Butler   \n",
      "4  A3C9V987IQHOQD                                          Rjostler   \n",
      "5  A3J5NN6MJK4M4A         Aubrie A. Dionne \"Fantasy, Sci Fi Author\"   \n",
      "6   A531QY5K7JVXI                                           Chicano   \n",
      "7    AN8ELR6AHMMQ  Jessss \"I read to find stories that inspire m...   \n",
      "\n",
      "                                             summary  unixReviewTime  \\\n",
      "1                            Terrific menage scenes!      1381190400   \n",
      "4                                               Book      1356912000   \n",
      "5          A story of a little girl with big dreams.      1260144000   \n",
      "6  This story has potential but ultimately disapp...      1313625600   \n",
      "7                                      Good thriller      1268006400   \n",
      "\n",
      "   Sentiment  \n",
      "1        1.0  \n",
      "4        1.0  \n",
      "5        1.0  \n",
      "6        0.0  \n",
      "7        1.0  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(df['reviewText'])\n",
    "y = df['Sentiment']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "df['reviewText_Tokens'] = df['reviewText'].apply(lambda x: x.split())\n",
    "\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=df['reviewText_Tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_word2vec_vector(text):\n",
    "    vector = [word2vec_model.wv[word] for word in text if word in word2vec_model.wv]\n",
    "    return sum(vector) / len(vector) if vector else np.zeros(100)\n",
    "\n",
    "X_word2vec = np.array(df['reviewText_Tokens'].apply(get_word2vec_vector).tolist())\n",
    "y = df['Sentiment']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier\n",
    "    1.Split the dataset into train and test sets\n",
    "    2.Train a Logistic Regression classifier\n",
    "    3.Predict on the test set\n",
    "    4.# Evaluate the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full code with TD-IFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full code with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\M.Vishnu\n",
      "[nltk_data]     Balaji\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"G:\\\\step_intern\\\\all_kindle_review.csv\")\n",
    "\n",
    "# Add the Sentiment column based on the rating\n",
    "# Ratings 4 and 5 are considered positive (1), 1 and 2 are negative (0)\n",
    "df['Sentiment'] = df['rating'].apply(lambda x: 1 if x > 3 else (0 if x < 3 else None))\n",
    "\n",
    "# Drop neutral reviews (rating = 3)\n",
    "df.dropna(subset=['Sentiment'], inplace=True)\n",
    "\n",
    "# Preprocess text\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Tokenize the review text\n",
    "df['reviewText_Tokens'] = df['reviewText'].apply(lambda x: x.split())\n",
    "\n",
    "# Train a Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=df['reviewText_Tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Convert review text to Word2Vec vectors\n",
    "def get_word2vec_vector(text):\n",
    "    vector = [word2vec_model.wv[word] for word in text if word in word2vec_model.wv]\n",
    "    return sum(vector) / len(vector) if vector else np.zeros(100)\n",
    "\n",
    "X_word2vec = np.array(df['reviewText_Tokens'].apply(get_word2vec_vector).tolist())\n",
    "y = df['Sentiment']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_word2vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
